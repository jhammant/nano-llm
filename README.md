# Nano-Llama: Fine-Tuned LLM for Nano Cryptocurrency

## ğŸš€ Overview
This project fine-tunes the **DeepSeek LLM** model on Nano cryptocurrency documentation. It enables the model to answer Nano-related queries while linking to relevant documentation.

## ğŸ› ï¸ Installation & Setup
### **1ï¸âƒ£ Install Dependencies**
First, install Python packages:
```bash
pip install -r requirements.txt
```

### **2ï¸âƒ£ Set Up GitHub Token (For Documentation Fetching)**
Since the script fetches documentation from GitHub, export your token **(DO NOT hardcode it)**:
```bash
export GITHUB_TOKEN="ghp_your_actual_token_here"
```
If you want it to persist:
```bash
echo 'export GITHUB_TOKEN="ghp_your_actual_token_here"' >> ~/.zshrc
source ~/.zshrc
```

---
## âš¡ Running the Scripts
### **1ï¸âƒ£ Fetch Nano Documentation**
```bash
python3 download_nano_docs.py
```
This script downloads Nano-related markdown files from GitHub and processes them into a JSONL dataset.

### **2ï¸âƒ£ Generate Documentation URLs**
```bash
python3 fetch_nano_doc_urls.py
```
This script scrapes `https://docs.nano.org/` to extract valid URLs for linking in responses.

### **3ï¸âƒ£ Preprocess & Clean Dataset**
```bash
python3 clean_jsonl.py
```
This ensures the dataset is correctly formatted before fine-tuning.

### **4ï¸âƒ£ Fine-Tune the Model**
```bash
accelerate launch fine_tune.py
```
This fine-tunes the model using **DeepSeek LLM** with the Nano documentation.

---
## ğŸ“‚ Project Structure
```
ğŸ“ nano-llama
â”œâ”€â”€ download_nano_docs.py   # Fetches Nano markdown docs from GitHub
â”œâ”€â”€ fetch_nano_doc_urls.py  # Scrapes Nano documentation site URLs
â”œâ”€â”€ clean_jsonl.py          # Cleans and formats the dataset
â”œâ”€â”€ fine_tune.py            # Fine-tuning script using Hugging Face Trainer
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ .gitignore              # Excludes model weights, cache, and logs
â”œâ”€â”€ README.md               # This file
```

---
## ğŸ“œ Notes
- **Model weights are NOT included in the repo** to avoid large file commits.
- Fine-tuning is done on **Apple Silicon MPS (Mac GPU)**.
- To keep responses Nano-focused, system prompts & fine-tuning guide responses away from unrelated topics.

ğŸš€ **Enjoy your Nano LLM!**
